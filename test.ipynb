{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "adb841b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import tensorflow as tf\n",
    "def histo_equalized_batch(imgs):\n",
    "    assert (len(imgs.shape) == 4)  # 4D arrays\n",
    "    assert (imgs.shape[1] == 1)  # check the channel is 1\n",
    "    imgs_equalized = np.empty(imgs.shape)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_equalized[i, 0] = cv2.equalizeHist(np.array(imgs[i, 0], dtype=np.uint8))\n",
    "    return imgs_equalized\n",
    "\n",
    "\n",
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "# adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\" (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual. So in a small area, histogram would confine to a small region (unless there is noise). If noise is there, it will be amplified. To avoid this, contrast limiting is applied. If any histogram bin is above the specified contrast limit (by default 40 in OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is applied\n",
    "def clahe_equalized_batch(imgs):\n",
    "    assert (len(imgs.shape) == 4)  # 4D arrays\n",
    "    # assert (imgs.shape[1]==1)  #check the channel is 1\n",
    "    # create a CLAHE object (Arguments are optional).\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    imgs_equalized = np.empty(imgs.shape)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_equalized[i, 0] = clahe.apply(np.array(imgs[i, 0], dtype=np.uint8))\n",
    "    return imgs_equalized\n",
    "\n",
    "\n",
    "# ===== normalize over the dataset\n",
    "def dataset_normalized_batch(imgs):\n",
    "    assert (len(imgs.shape) == 4)  # 4D arrays\n",
    "    # assert (imgs.shape[1]==1)  #check the channel is 1\n",
    "    imgs_normalized = np.empty(imgs.shape)\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs - imgs_mean) / imgs_std\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_normalized[i] = ((imgs_normalized[i] - np.min(imgs_normalized[i])) / (\n",
    "                    np.max(imgs_normalized[i]) - np.min(imgs_normalized[i]))) * 255\n",
    "    return imgs_normalized\n",
    "\n",
    "def adjust_gamma_batch(imgs, gamma=1.0):\n",
    "    assert (len(imgs.shape) == 4)  # 4D arrays\n",
    "    # assert (imgs.shape[1]==1)  #check the channel is 1\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # apply gamma correction using the lookup table\n",
    "    new_imgs = np.empty(imgs.shape)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        new_imgs[i, 0] = cv2.LUT(np.array(imgs[i, 0], dtype=np.uint8), table)\n",
    "    return new_imgs\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    assert (len(rgb.shape) == 4)  # 4D arrays\n",
    "    assert (rgb.shape[1] == 3)\n",
    "    bn_imgs = rgb[:, 1, :, :] * 0.75 + rgb[:, 2, :, :] * 0.25\n",
    "    bn_imgs = np.reshape(bn_imgs, (rgb.shape[0], 1, rgb.shape[2], rgb.shape[3]))\n",
    "    return bn_imgs\n",
    "\n",
    "def preprocess_batch(data):\n",
    "    assert (len(data.shape) == 4)\n",
    "    assert (data.shape[1] == 3)  # Use the original images\n",
    "    train_imgs = rgb2gray(data)\n",
    "    # my preprocessing:\n",
    "    train_imgs = dataset_normalized_batch(train_imgs)\n",
    "    train_imgs = clahe_equalized_batch(train_imgs)\n",
    "    train_imgs = adjust_gamma_batch(train_imgs, 1.2)\n",
    "    return train_imgs\n",
    "\n",
    "def make_patches(images, size=64, offset_y=0, offset_x=0):\n",
    "    \"\"\"\n",
    "    Split images into patches for processing with optional offset.\n",
    "    \n",
    "    Args:\n",
    "        images: ndarray, shape (N, C, H, W)\n",
    "        size: block size (patch dimensions)\n",
    "        offset_y: vertical offset from multiples of size (0 to size-1)\n",
    "        offset_x: horizontal offset from multiples of size (0 to size-1)\n",
    "    \n",
    "    Returns:\n",
    "        patches: ndarray, shape (num_patches, C, size, size)\n",
    "        info: metadata tuple for reconstruction\n",
    "    \"\"\"\n",
    "    images = np.asarray(images)\n",
    "    N, C, H, W = images.shape\n",
    "    \n",
    "    # Validate offsets\n",
    "    offset_y = max(0, min(offset_y, size - 1))\n",
    "    offset_x = max(0, min(offset_x, size - 1))\n",
    "    \n",
    "    # Calculate number of blocks needed considering offset\n",
    "    nH = math.ceil((H - offset_y) / size)\n",
    "    nW = math.ceil((W - offset_x) / size)\n",
    "    \n",
    "    # Calculate required padding\n",
    "    required_H = offset_y + nH * size\n",
    "    required_W = offset_x + nW * size\n",
    "    \n",
    "    padH = max(0, required_H - H)\n",
    "    padW = max(0, required_W - W)\n",
    "    \n",
    "    # Pad images\n",
    "    padded = np.pad(images, ((0,0),(0,0),(0,padH),(0,padW)), mode='constant')\n",
    "    \n",
    "    patches = []\n",
    "    for n in range(N):\n",
    "        for i in range(nH):\n",
    "            for j in range(nW):\n",
    "                y = offset_y + i * size\n",
    "                x = offset_x + j * size\n",
    "                block = padded[n, :, y:y+size, x:x+size]\n",
    "                patches.append(block)\n",
    "    \n",
    "    patches = np.stack(patches, axis=0)\n",
    "    info = (H, W, nH, nW, padded.shape, offset_y, offset_x)\n",
    "    return patches, info\n",
    "\n",
    "def reconstruct_from_patches(patches, info, size=64):\n",
    "    \"\"\"\n",
    "    Reconstruct images from patches with offset support.\n",
    "    \n",
    "    Args:\n",
    "        patches: ndarray, shape (num_patches, C, size, size)\n",
    "        info: metadata tuple from make_patches\n",
    "        size: block size\n",
    "    \n",
    "    Returns:\n",
    "        reconstructed images: ndarray, shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "    if len(info) == 7:  # New format with offsets\n",
    "        H, W, nH, nW, padded_shape, offset_y, offset_x = info\n",
    "    else:  # Old format without offsets (backward compatibility)\n",
    "        H, W, nH, nW, padded_shape = info\n",
    "        offset_y, offset_x = 0, 0\n",
    "    \n",
    "    N = padded_shape[0]\n",
    "    C = padded_shape[1]\n",
    "    padded_H, padded_W = padded_shape[2], padded_shape[3]\n",
    "    \n",
    "    # Initialize reconstruction arrays\n",
    "    recon = np.zeros(padded_shape, dtype=patches.dtype)\n",
    "    counts = np.zeros(padded_shape, dtype=np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    for n in range(N):\n",
    "        for i in range(nH):\n",
    "            for j in range(nW):\n",
    "                y = offset_y + i * size\n",
    "                x = offset_x + j * size\n",
    "                recon[n, :, y:y+size, x:x+size] += patches[idx]\n",
    "                counts[n, :, y:y+size, x:x+size] += 1\n",
    "                idx += 1\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    counts[counts == 0] = 1\n",
    "    recon = recon / counts\n",
    "    \n",
    "    # Crop back to original dimensions\n",
    "    return recon[:, :, :H, :W]\n",
    "def remove_islands(image, minsize=50):\n",
    "    \"\"\"\n",
    "    Remove small islands (connected components) from a binary image.\n",
    "    \n",
    "    Args:\n",
    "        image: binary image (2D array)\n",
    "        minsize: minimum size of connected components to keep\n",
    "    \n",
    "    Returns:\n",
    "        cleaned_image: binary image with small islands removed\n",
    "    \"\"\"\n",
    "    assert len(image.shape) == 2, \"Input must be a 2D binary image\"\n",
    "    \n",
    "    # Find connected components\n",
    "    num_labels, labels_im = cv2.connectedComponents(image.astype(np.uint8), connectivity=8)\n",
    "    \n",
    "    # Create an output image\n",
    "    cleaned_image = np.zeros_like(image, dtype=np.uint8)\n",
    "    \n",
    "    for label in range(1, num_labels):  # Skip label 0 (background)\n",
    "        component_size = np.sum(labels_im == label)\n",
    "        if component_size >= minsize:\n",
    "            cleaned_image[labels_im == label] = 1\n",
    "    \n",
    "    return cleaned_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8bc0c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbce_dice_loss(y_true, y_pred, eps=1e-6):\n",
    "    \"\"\"\n",
    "    y_true: ground‐truth mask, shape (B, H, W, 1), values in {0,1}\n",
    "    y_pred: predicted mask logits or probabilities, same shape\n",
    "    \"\"\"\n",
    "    # flatten spatial dims to compute N and n per sample\n",
    "    y_true_f = tf.reshape(y_true, (tf.shape(y_true)[0], -1))\n",
    "    y_pred_f = tf.reshape(y_pred, (tf.shape(y_pred)[0], -1))\n",
    "    \n",
    "    # per‐sample sums\n",
    "    n = tf.reduce_sum(y_true_f, axis=1)                       # shape (B,)\n",
    "    N = tf.cast(tf.shape(y_true_f)[1], tf.float32)           # scalar\n",
    "    \n",
    "    # 1) binary cross‐entropy per sample\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true_f, y_pred_f)  # shape (B,)\n",
    "    \n",
    "    # 2) dice loss per sample\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=1)      # shape (B,)\n",
    "    dice_coef = (2. * intersection + eps) / (n + tf.reduce_sum(y_pred_f, axis=1) + eps)\n",
    "    dice_loss = 1. - dice_coef                                     # shape (B,)\n",
    "    \n",
    "    # 3) weighting term per sample\n",
    "    w_bce  = (N - n) / N    # shape (B,)\n",
    "    w_dice = n     / N      # shape (B,)\n",
    "    \n",
    "    # 4) combined loss, then mean over batch\n",
    "    loss_per_sample = w_bce * bce + w_dice * dice_loss            # shape (B,)\n",
    "    return tf.reduce_mean(loss_per_sample)\n",
    "custom = {\n",
    "    # 'CascadeUnet': CascadeUnet,\n",
    "    'lbce_dice_loss': lbce_dice_loss,\n",
    "    # 'combined_loss': combined_loss,\n",
    "    # 'dice_coef': dice_coef,\n",
    "\n",
    "}\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    \"model8_4no2\",\n",
    "    # onnly use weights\n",
    "\n",
    "    custom_objects=custom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "39079403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\exp2\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider '' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** EP Error ***************\n",
      "EP Error Unknown Provider Type:  when using ['']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "Preprocessed image shape: (1, 1, 600, 1200)\n",
      "Visit counts computed.\n",
      "(600, 1200)\n",
      "Processing time: 1.44 seconds\n",
      "percentage of pixels predicted as positive: 8.394583333333333\n",
      "This image is likely a bad image.\n"
     ]
    }
   ],
   "source": [
    "# %pip install onnxruntime\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_and_predict_image(\n",
    "    image_path,\n",
    "    patch_size=64,\n",
    "    resize_shape=None,\n",
    "    offsets=None,\n",
    "    session=None,          # <-- pass an onnxruntime.InferenceSession\n",
    "    plot=True,\n",
    "    threshold=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Requires the following helpers to exist in your environment:\n",
    "      - preprocess_batch(NCHW_batch) -> NCHW_batch\n",
    "      - make_patches(NCHW_batch, size, offset_y, offset_x) -> (patches_NCHW, info)\n",
    "      - reconstruct_from_patches(patches_NCHW, info, size) -> NCHW image\n",
    "      - remove_islands(binary_2d_array, minsize)\n",
    "    \"\"\"\n",
    "    if session is None:\n",
    "        raise ValueError(\"Please pass an onnxruntime.InferenceSession via `session`.\")\n",
    "\n",
    "    if offsets is None:\n",
    "        offsets = [(0, 0), (24, 24)]\n",
    "\n",
    "    # --- helpers -------------------------------------------------------------\n",
    "    def get_pixel_visit_counts_from_offsets(image_shape, patch_size, offsets):\n",
    "        H, W = image_shape\n",
    "        dummy = np.zeros((1, 1, H, W), dtype=np.uint8)\n",
    "        total_counts = np.zeros((1, 1, H, W), dtype=np.int32)\n",
    "\n",
    "        for offset_y, offset_x in offsets:\n",
    "            _, info = make_patches(dummy, size=patch_size, offset_y=offset_y, offset_x=offset_x)\n",
    "            recon = reconstruct_from_patches(\n",
    "                np.ones((info[2] * info[3], 1, patch_size, patch_size), dtype=np.uint8),\n",
    "                info, size=patch_size\n",
    "            )\n",
    "            total_counts += recon.astype(np.int32)\n",
    "\n",
    "        return total_counts[0, 0]\n",
    "\n",
    "    def _infer_expected_layout_and_name(sess):\n",
    "        # Detect the single input’s name and expected layout (NCHW vs NHWC)\n",
    "        inp = sess.get_inputs()[0]\n",
    "        name = inp.name\n",
    "        shape = inp.shape  # may contain None/strings for dynamic dims\n",
    "        layout = \"NHWC\"  # sensible default\n",
    "\n",
    "        if isinstance(shape, (list, tuple)) and len(shape) == 4:\n",
    "            c1 = shape[1]\n",
    "            c3 = shape[3]\n",
    "            # If either dimension is clearly 1 or 3, assume that’s channels\n",
    "            if c1 in (1, 3):\n",
    "                layout = \"NCHW\"\n",
    "            elif c3 in (1, 3):\n",
    "                layout = \"NHWC\"\n",
    "        return name, layout\n",
    "\n",
    "    def _to_float01(x):\n",
    "        # Ensure float32 in [0,1]\n",
    "        x = x.astype(np.float32, copy=False)\n",
    "        # If values look like 0..255, normalize; otherwise assume already normalized\n",
    "        if x.max() > 1.5:\n",
    "            x = x / 255.0\n",
    "        return x\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    # Load and preprocess image (to NCHW because your patch code expects NCHW)\n",
    "    image = cv2.imread(image_path)\n",
    "    if resize_shape is not None:\n",
    "        image = cv2.resize(image, resize_shape)\n",
    "    image_save = image.copy()\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)      # (N, H, W, C)\n",
    "    image = image.transpose(0, 3, 1, 2)        # -> (N, C, H, W)\n",
    "    image = preprocess_batch(image)            # user-defined\n",
    "\n",
    "    print(f\"Preprocessed image shape: {image.shape}\")  # (1, C, H, W)\n",
    "\n",
    "    visits = get_pixel_visit_counts_from_offsets(image.shape[2:], patch_size, offsets)\n",
    "    print(\"Visit counts computed.\")\n",
    "\n",
    "    input_name, expected_layout = _infer_expected_layout_and_name(session)\n",
    "\n",
    "    predicted_images = []\n",
    "    for (x_off, y_off) in offsets:\n",
    "        # Patches come out as NCHW\n",
    "        patches, info = make_patches(image, size=patch_size, offset_y=y_off, offset_x=x_off)\n",
    "\n",
    "        # Prepare input batch for ONNX model\n",
    "        if expected_layout == \"NHWC\":\n",
    "            to_model = patches.transpose(0, 2, 3, 1)  # NCHW -> NHWC\n",
    "        else:  # NCHW expected\n",
    "            to_model = patches\n",
    "\n",
    "        to_model = _to_float01(to_model)\n",
    "\n",
    "        # Run ONNX inference\n",
    "        outputs = session.run(None, {input_name: to_model})\n",
    "        preds = outputs[0]\n",
    "\n",
    "        # Normalize preds to NCHW for reconstruction\n",
    "        if preds.ndim == 4:\n",
    "            if preds.shape[1] in (1, 3):        # NCHW\n",
    "                preds_nchw = preds\n",
    "            elif preds.shape[-1] in (1, 3):     # NHWC\n",
    "                preds_nchw = preds.transpose(0, 3, 1, 2)\n",
    "            else:\n",
    "                # Unknown 4D layout; assume NHWC as fallback\n",
    "                preds_nchw = preds.transpose(0, 3, 1, 2)\n",
    "        elif preds.ndim == 3:\n",
    "            # (N, H, W) -> add channel dim\n",
    "            preds_nchw = preds[:, None, :, :]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected ONNX output shape: {preds.shape}\")\n",
    "\n",
    "        # Reconstruct full-size prediction for this offset\n",
    "        recon = reconstruct_from_patches(preds_nchw, info, size=patch_size)\n",
    "        recon = recon.squeeze().astype(np.float32)  # -> (H, W)\n",
    "\n",
    "        predicted_images.append(recon)\n",
    "\n",
    "    # Blend offset predictions by visit counts\n",
    "    sum_predictions = np.sum(predicted_images, axis=0)\n",
    "\n",
    "    visits = visits.astype(np.float32)\n",
    "    visits[visits == 0] = 1.0\n",
    "\n",
    "    full_pred = sum_predictions / visits\n",
    "    full_pred = (full_pred > threshold).astype(np.float32)\n",
    "    full_pred = remove_islands(full_pred, minsize=250)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(full_pred, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image_save, cmap='gray')\n",
    "        plt.imshow(full_pred, cmap='winter', alpha=0.1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(image_save, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return full_pred\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    session = ort.InferenceSession(r\"VSeg_64p.onnx\", providers=[\"\"])\n",
    "\n",
    "    image_path = r\"C:\\Users\\NateLy\\retina\\testimgs\\live_rec_test\\live_rec_test\\Integration_CT_L1_85.tif\"\n",
    "    # image_path = r\"C:\\Users\\NateLy\\Downloads\\elka_00.tif\"\n",
    "    # image_path = r\"C:\\Users\\NateLy\\retina\\testimgs\\epy_img_20220828_1143_38_alligned.bmp\"\n",
    "    patch_size = 64\n",
    "    resize_shape = None\n",
    "    offsets = [(0, 0), (24,24)]  # Offsets for patch extraction\n",
    "    threshold = 0.1  # Use a threshold for binary prediction\n",
    "    start = time.time()\n",
    "    plot = False  # Set to False to disable plotting\n",
    "    full_pred = process_and_predict_image(image_path, patch_size, resize_shape, offsets, session, threshold=threshold, plot=plot)\n",
    "    print(full_pred.shape)\n",
    "    print(f\"Processing time: {time.time() - start:.2f} seconds\")\n",
    "    mean_white = np.mean(full_pred) * 100\n",
    "    print(\"percentage of pixels predicted as positive:\", mean_white)\n",
    "    # if below percentage threshold     \n",
    "    if mean_white > 10:\n",
    "        print(\"This image is likely a good image.\")\n",
    "    else:\n",
    "        print(\"This image is likely a bad image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f6f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310d288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
